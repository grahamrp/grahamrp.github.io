---
layout: post
title: "University Clustering using the Guardian University Guide 2015: Part 2"
date: 2014-10-05 
thumbnail: assets/cluster_thumbnail.png
---

This is the second in a two-part series of posts about clustering universities using data from the Guardian University Guide 2015. I'll be addressing the following

- Are there any clear clusters of universities based on the Guardian metrics?
- If so, do the clusters have any interesting characteristics?

In [Part 1]({% post_url 2014-09-14-clustering-universities-with-guardian-2015-part-1 %}) I described the hierarchical clustering technique and the use of dendrograms to visualise the results. Now in Part 2 I'll prepare the university data, cluster the universities, and look at the results.

A full explanation of the Guardian's measures is provided [here](http://www.theguardian.com/education/2014/jun/03/how-to-use-guardian-university-guide) but briefly the 8 measures are:

- **Course satisfaction**: the percentage of final-year students who agree with the statement "Overall, I am satisfied with the quality of the course" in the [National Student Survey](http://www.thestudentsurvey.com)(NSS).
- **Teaching quality**: the percentage of final-year students satisfied with the teaching they received, based on 4 related NSS questions
- **Feedback**: the percentage of final-years satisfied with feedback and assessment by lecturers, based on 5 related NSS questions
- **Staff/student ratio**: the number of students per member of teaching staff
- **Spend**: the amount of money spent on each student, given as a rating out of 10
- **Average entry tariff**: the average [UCAS tariff](http://www.ucas.com/how-it-all-works/explore-your-options/entry-requirements/ucas-tariff) scores for new students
- **Value-added**: a score from 1 - 10 representing the extent to which students enter the university with relatively low qualifications and graduate with high ones
- **Career**: the percentage of graduates who find graduate-level jobs, or are studying further, within six months of graduation, as determined by the [Destinations of Leavers Survey](https://www.hesa.ac.uk/index.php?option=com_content&view=article&id=1899&Itemid=634)

Preparing the data
------------------

The Guardian do a great job of providing their university data in an easy to use format. The 2014 data are provided on the Guardian [Datablog](http://www.theguardian.com/news/datablog) via a Google Doc [here](https://docs.google.com/spreadsheets/d/1BY2Slb3OEr_Pl1CVmxE4nWTZDxu1FSTP0FXyPU2lLYI/edit?pli=1), which can be downloaded as an Excel&reg; workbook.

The data need a bit of preparation before clustering. Firstly the data need to be liberated from the Excel workbook and then the "Ranking" column needs to be parsed. This column contains rankings for the last three years in the format "rank2013  → rank2014 → rank2015", which needs to be split out into separate columns. The rankings might not be used for this analysis, but it doesn't hurt to parse them into a useable format. Also the column headings will be given more succinct names.

```{r load_libs, message = FALSE, warning = FALSE}
# load required packages
library(XLConnect)  # for reading Excel
library(stringr)  # string manipulation
library(stringi)  # for character encoding conversion
library(dplyr)  # data manipulation
library(reshape2)  # data manipulation
library(ggplot2)  # data visualisation
library(ape)  # producing nice cluster diagrams
library(knitr)  # for table formatting (kable)
```

```{r prep_data, eval=TRUE, message=FALSE, warning=FALSE, cache=FALSE}
wb2015 <- loadWorkbook("data/originals/Undergraduate Guardian University Guide 2015.xlsx")
table2015 <- readWorksheet(wb2015, sheet = "Institution", header = TRUE, startRow = 3)

# split out column 1 into 3 columns
mat <- matrix(unlist(strsplit(table2015$Ranking, " → ")), ncol = 3, byrow = TRUE)
table2015$Ranking <- NULL  # delete original composite column
df <- as.data.frame(mat)
colnames(df) <- c('rank2013','rank2014','rank2015')
table2015 <- cbind(df, table2015)
# convert ranks from text to numbers
table2015$rank2013 <- as.numeric(as.character(table2015$rank2013))
table2015$rank2014 <- as.numeric(as.character(table2015$rank2014))
table2015$rank2015 <- as.numeric(as.character(table2015$rank2015))

names(table2015) <- c('rank13','rank14','rank15','institution','score','nss.teach',
                      'nss.all','spend','ssr','career','value','tariff','nss.feedback')

# replace Glyndŵr with Glyndwr since cluster plotter does not like it
table2015$institution <- stri_trans_general(table2015$institution, 'Latin-ASCII')

# remove University Campus Suffolk since it does not have a full set of measures
table2015 <- table2015[table2015$institution != 'University Campus Suffolk', ]
```

The data now look like this:

```{r show_data, results='asis' }
kable(head(table2015), format = 'markdown')
```

The data are ready to be put into the right shape for hierarchical clustering. This means creating a new dataframe containing just the measures used to produce the scores (not the overall score or the rankings), and *scaling* these scores so that they are all on a comparable scale. Without scaling the scores universities would be considered equally far apart if they had a difference of 10 in student satisfaction or 10 in UCAS tariff points, but a 10 percentage point difference in satisfaction is huge whereas a 10 point increase in average UCAS tariff pretty small.

```{r prep_for_clustering}
clustdata <- table2015
# move institution names to rownames
row.names(clustdata) <- paste0(clustdata$institution, ' (', clustdata$rank15, ')')
#row.names(clustdata) <- clustdata$institution

# remove superflous columns
to_keep <- c('nss.teach','nss.all','spend','ssr','career','value','tariff','nss.feedback')
clustdata <- clustdata[, to_keep]

# invert the student/staff ratio to be staff/student ratio
# the result is that for all measures "higher is better"
# this is not necessary for clustering but might be useful in later analyses
clustdata$ssr <- 1 / clustdata$ssr

# scale the data (subtract mean and then divide by standard deviation)
scaled <- as.data.frame(scale(clustdata))
```

The data now look like this:

```{r show_scaled_data, results='asis'}
kable(round(head(scaled),1), format = 'markdown')
```

Now that the data are scaled it's actually easier to compare institutions with each other and across the measures. The scores are now "number of standard deviations from the average", with positive values being above average and negative below. We can see from the top 6 universities above nearly all the scores are above average, as would be expected from the top performers, with one interesting exception that Imperial College scores just below average on NSS Feedback (-0.4 on the scaled score). Across measures it's easy to see which are the really strong points for an institution, for example Cambridge are only just above average on *value* (0.4) but are exceptionally high on *tariff* (3.1).

Clustering
----------

The first step in hierarchical clustering is to calculate the distances between universities using the 8 measures in the dataset. The resultant distance matrix is then fed into the clustering function and the results are plotted.

```{r basic_cluster, fig.height=10, fig.width=14, warning=FALSE}

distances <- dist(scaled)
hcluster <- hclust(distances)
plot(hcluster,
     cex = 0.8,  # reduce size of labels
     ann = FALSE)  # remove annotations
```

### How many clusters?

The number of clusters shown by the dendrogram above is somewhat subjective, and dependent on what we want to use the results for. I want to see if there are relatively large groupings of universities -- whether or not they fit into a small number of "types". It looks to me as though there are 2 or 3 clusters. Slicing across the graph at 10 on the y-axis would break the dendrogram into the 2 most distinct clusters, and slicing across the graph at about 7 would break the dendrogram into 3 clusters:

```{r show_clusters, fig.height=3, fig.width=8, warning=FALSE}
par(mfcol = c(1, 2))  
# highlight 2 clusters
plot(hcluster,
     labels = FALSE,  # remove institution labels
     ann = FALSE)  # remove annotations
rect.hclust(hcluster, k = 2) 
title('Main 2 clusters', cex.main = 0.8)

# highlight 3 clusters
plot(hcluster,
     labels = FALSE,  # remove labels
     ann = FALSE)  # remove annotations
rect.hclust(hcluster, k = 3) 
title('Main 3 clusters', cex.main = 0.8) 
```

Taking a look at the main dendrogram we can see that the 2-cluster solution has identified the cluster of very strong institutions on the left, and "everyone else" on the right. The 3-cluster solution separates institutions into the very strong group on the left, a weaker group to the right of it, and "everyone else" further to the right. Interpreting the dataset as 4, 5 or more clusters could also yield some interesting groups.

A closer look at the clusters
-----------------------------

In order to investigate the clusters more fully I will switch to a more flexible plotting function provided by the `ape` package, which will allow colours to be added to encode additional information, and some cosmetic changes too.

To get a feel for the strong/weaker makeup of the groups I will colour the labels according to the overall league table position. I will also flip the diagram on its side to make reading the institution names easier.

```{r colour_by_rank, fig.width=8, fig.height=10}
colfunc <- colorRampPalette(c("black", "gray92"))  # colour gradient from dark to light
# institutions are in rank order so the colours can be passed directly to the plot
plot(as.phylo(hcluster), type = 'phylo', cex = 0.5, 
     tip.color = colfunc(nrow(scaled)),  
     font = 1, rotate.tree = 10, no.margin = TRUE)
```

As we might expect, the best-performing institutions can be seen clearly, at the bottom of the dendrogram as a band of dark grey. These fall into a distinct cluster since they will tend to perform well on all measures. Likewise, the adjacent light-grey band above it shows the worst-performing institutions, who tend to perform poorly on all measures. The remaining institutions are a bit more varied, perhaps excelling in one area but not doing so well in another, hence they are more "distant" from each other and appear as a less-distinctive cluster.

Another interesting cluster is the three institutions at the bottom -- King's College London, UCL and Edinburgh. These actually appear as a separate cluster if the dendrogram is split into 4. Taking a look at the standardised scores it looks as if these universities share higher than average scores in most of the measures, but worse than average in student satisfaction, particularly satisfaction with feedback (Edinburgh has the worst in the league).

```{r show_mini_cluster, results='asis'}
kable(scaled[grepl('College London|UCL|Edinburgh$', table2015$institution), ], 
      format = 'markdown')
```

Colouring by University group
-----------------------------

Many universities belong to "mission groups" that have similar market positions and ambitions. I thought it would be interesting to add some of the common mission groups to the clustering to see if there are any patterns. The groups I've selected are:

 - [Russell](https://en.wikipedia.org/wiki/Russell_Group): Research-intensive group of 24 institutions
 - [1994](https://en.wikipedia.org/wiki/1994_Group): Group of smaller research-intensive institutions, dissolved late 2013 but still useful as a grouping for this analysis
 - [Million+](https://en.wikipedia.org/wiki/Million%2B): Think-tank of 22 newer universities and colleges
 - [GuildHE](https://en.wikipedia.org/wiki/GuildHE): Group of newer universities and colleges tending to be smaller and having a specialism, e.g. art and design or sports
 - [University Alliance](https://en.wikipedia.org/wiki/University_Alliance): Group of newer universities focussing on the professions, science/tech and design, often keen on business engagement and employability of graduates.
 
 The following plot shows the same dendrogram, but this time coloured by the university mission group (or grey if the university does not belong to any of the above groups).

```{r coloured_by_group, fig.width=8, fig.height=10}
uni_groups <- read.delim('data/originals/University Groups.csv', 
                         stringsAsFactors = FALSE)
# replace Glyndŵr with Glyndwr to match league table dataframe
uni_groups$institution <- stri_trans_general(uni_groups$institution, 'Latin-ASCII')

table2015$group <- uni_groups[match(table2015$institution, uni_groups$institution), 
                              'group']

# vector of colours
group_colours <- data.frame(
  colour = c('grey','magenta','brown','navy','royalblue1','orange1'),
  group = c('','Million','Guild','Russell','1994','Alliance'), stringsAsFactors = F)

cols <- group_colours$colour[match(table2015$group, group_colours$group)]

plot(as.phylo(hcluster), type = 'phylo', cex = 0.5, 
     tip.color = cols,  
     font = 1, rotate.tree = 10, no.margin = TRUE)
legend('topleft', legend = group_colours$group, col = group_colours$colour, 
       fill = group_colours$colour, bty = 'n', border = 0, cex = 0.6)
```

The university names have been plotted over each other a bit because I am more concerned with the overall colours than any specific institution. What shows through quite clearly is the separation between the research-focussed groups (Russell, 1994) in blue vs. the others. There are two blue bands, one at the bottom in the high-performing cluster, and another nearer the top. Institutions not belonging to a group are spread throughout the clustering, and the Million+/GuildHE/Alliance groups tend to be fairly evenly mixed.

It can be difficult to differentiate between each cluster using the dendrogram above. It is also important to remember that the ordering of institutions in the dendrogram above is arbitrary, what matters is how they are connected to each other via the lines. As an alternative method of plotting, the `ape` packages gives more flexibility in presenting these hierarchical relationships. Plotting the universities in a radial layout helps to separate the groups out, and also has the benefit of making the y-axis unambiguously meaningless.

```{r coloured_by_group2, fig.width=10}
plot(as.phylo(hcluster), type = 'un', cex = 0.4, 
     tip.color = cols, lab4ut = 'axial', 
     font = 1, rotate.tree = 10, no.margin = TRUE)
legend('topleft', legend = group_colours$group, fill = group_colours$colour, 
       title = 'Coloured by Mission Group', bty = 'n', border = 0, cex = 0.6)
```

One group that looks interesting is the other "Russell/1994" cluster at the top-left of the above plot, which is identified as a distinct group once the dendrogram is split into 7. This corresponds to the green cluster 3 in the cluster diagram as illustrated below:

```{r coloured_by_cluster, fig.width=10}
plot(as.phylo(hcluster), type = 'un', cex = 0.4, 
     tip.color = cutree(hcluster, k = 7), lab4ut = 'axial', 
     font = 1, rotate.tree = 10, no.margin = TRUE)
legend('topleft', legend = 1:7, fill = 1:7, bty = 'n', border = 0, cex = 0.6,
       title = 'Coloured by Cluster Group')
```

The cluster is composed of the following institutions and measures:


```{r inspect_groups_1, results='asis'}
# the cluster of interest just happens to be number '3'
kable(scaled[cutree(hcluster, k = 7) == '3', ], 
      format = 'markdown')
```

They are all similarly ranked, but it's pretty tough to stare at the table to draw out any more commonalities. Even summarising the measures for each group doesn't make things much easier:

```{r inspect_groups_2, results='asis'}
# create separate dataframe with cluster membership added
scaled_with_groups <- scaled
scaled_with_groups$clust_group7 <- cutree(hcluster, k = 7)

# calculate the mean of each column for each group
group_summary <- scaled_with_groups %>%
  group_by(clust_group7) %>%
  summarise_each(funs(mean))

kable(group_summary, format = 'markdown')
```

Rather than stare at the numbers, visualising the spread of each variable within each group should give some clues as to why the universities in similar mission groups (Russell/1994) have been placed into different clusters (clusters 1 and 3).

```{r plot_group7, fig.width=10}
# reshape the data
molten <- melt(scaled_with_groups, id.vars = "clust_group7")

ggplot(molten[molten$clust_group7 %in% c(1, 3),], 
       aes(x = value, col = as.factor(clust_group7))) + 
  geom_density() + 
  facet_wrap(~variable) + 
  scale_color_discrete('Cluster', labels = c('Russell/1994 Top-performers (group 1)', 
                                             'Russell/1994 Good-performers (group 3)')) +
  theme_bw()
```

Cluster 3 has a similar profile to the cluster 1 across each measure, but consistently lags behind slightly. The other main difference is in student/staff ratio where cluster 1 has more of a spread from slightly below average to way above average, whereas cluster 3 tends to have institutions with an SSR of just above average. 


```{r coloured_by_group_pretty, eval=FALSE, echo=FALSE}
# clusters in the right hand side of plot should be (rank) name instead of name (rank)
# this makes the plot prettier for the article picture (but not part of analysis)

# the clusters to the right (when split into 7) are 4, 5 and 7
rank <- str_extract(row.names(scaled_with_groups), "\\([0-9]+\\)" )
uni <- str_trim(str_extract(row.names(scaled_with_groups), "[A-Za-z ',]+ " ))
hcluster$labels <- ifelse(scaled_with_groups$clust_group7 %in% c(4,5,7), paste(rank, uni), paste(uni, rank))

plot(as.phylo(hcluster), type = 'un', cex = 0.4, 
     tip.color = cols, lab4ut = 'axial', 
     font = 1, rotate.tree = 10, no.margin = TRUE)
```

Conclusion
----------

That concludes my brief look at clustering universities using data from the Guardian University Guide 2015. Hierarchical clustering provides an interesting perspective into the data, for example showing how clearly delineated the research-intensive universities are from the others, despite there not being a research-related measure in the Guardian's league table, and also that there appear to be two distinct sets of the research-intensive universities, with one lagging slightly behind the other on most measures.
